{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9w5VPbGCfrKATs8DYPEft",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanarayan/EPAM_PRACTICE/blob/main/PracticeEPAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "kuTwHbixw97v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxGPRKL9qS_S"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext\n",
        "import csv,json , re\n",
        "from io import StringIO\n",
        "# Check if a SparkContext already exists\n",
        "try:\n",
        "    sc = SparkContext.getOrCreate()\n",
        "    print(\"Using existing SparkContext\")\n",
        "except ValueError:\n",
        "    # If not, create a new one\n",
        "    sc = SparkContext(\"local\", \"Linkdin Example\")\n",
        "    print(\"Created a new SparkContext\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd  = sc.textFile(\"/content/LinkedIn people profiles datasets.csv\")\n",
        "rdd_raw = rdd.map(lambda line: line.replace(',\"', '\\t\"'))\n",
        "print (rdd_raw.take(2))"
      ],
      "metadata": {
        "id": "dF7ElJSt1MO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8681b7a-cb15-4e35-cd9a-198618e6b5a8"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\"timestamp\"\\t\"id\"\\t\"name\"\\t\"city\"\\t\"country_code\"\\t\"region\"\\t\"current_company:company_id\"\\t\"current_company:name\"\\t\"position\"\\t\"following\"\\t\"about\"\\t\"posts\"\\t\"groups\"\\t\"current_company\"\\t\"experience\"\\t\"url\"\\t\"people_also_viewed\"\\t\"educations_details\"\\t\"education\"\\t\"avatar\"\\t\"languages\"\\t\"certifications\"\\t\"recommendations\"\\t\"recommendations_count\"\\t\"volunteer_experience\"\\t\"сourses\"', '\"2023-01-10\"\\t\"catherinemcilkenny\"\\t\"Catherine Fitzpatrick (McIlkenny), B.A\"\\t\"Canada\"\\t\"CA\"\\t\"NA\"\\t\"null\"\\t\"\"\\t\"Snr Business Analyst at Emploi et Développement social Canada (EDSC) / Employment and Social Development Canada (ESDC)\"\\t\"null\"\\t\"null\"\\t\"[{\"\"attribution\"\":\"\"Liked by Catherine Fitzpatrick (McIlkenny), B.A\"\"\\t\"\"img\"\":\"\"https://media.licdn.com/dms/image/C5622AQGesy-cKVfCaA/feedshare-shrink_2048_1536/0/1668547197397?e=2147483647&v=beta&t=hK5L_Ky-Ox4m90KT5u-roJB4C6BtWmD5UnOxYRvMucI\"\"\\t\"\"link\"\":\"\"https://www.linkedin.com/posts/esdcedsc_esw2022-activity-6998394190682341376-nMQh\"\"\\t\"\"title\"\":\"\"It’s never too late to open an RESP. Find out how a little can go a long way for a child’s education and how saving can set them up for success!…\"\"},{\"\"attribution\"\":\"\"Liked by Catherine Fitzpatrick (McIlkenny), B.A\"\"\\t\"\"img\"\":\"\"https://media.licdn.com/dms/image/C4E22AQHMWUhPL9AG5A/feedshare-shrink_800/0/1667668831230?e=2147483647&v=beta&t=LdI-tVu3yyWKpIm6MOsjYY0rsLMsLMjglOXvgjxPdyw\"\"\\t\"\"link\"\":\"\"https://www.linkedin.com/posts/kerrysurman_students-putting-into-practice-their-marketing-activity-6995574843446337537-cZoF\"\"\\t\"\"title\"\":\"\"Students putting into practice their marketing and presentation skills for a client in our community: Ottawa Tennis and Lawn Bowling Club. Be our…\"\"},{\"\"attribution\"\":\"\"Liked by Catherine Fitzpatrick (McIlkenny), B.A\"\"\\t\"\"img\"\":\"\"https://media.licdn.com/dms/image/C4E22AQFlJfcXvyuokg/feedshare-shrink_800/0/1662661343698?e=2147483647&v=beta&t=MYAObo49YVkQ8VbYbTKogX-THoO7g21uLwT4g7zh2_g\"\"\\t\"\"link\"\":\"\"https://www.linkedin.com/posts/jessica-m-bacon_today-i-return-to-work-after-my-second-incredible-activity-6973707126972022785-oO3J\"\"\\t\"\"title\"\":\"\"Today, I return to work after my second incredible maternity leave. I look forward to getting to know new faces, catching up with familiar faces and…\"\"}]\"\\t\"\"\\t\"{\"\"name\"\":\"\"\"\"}\"\\t\"\"\\t\"https://www.linkedin.com/in/catherinemcilkenny\"\\t\"[{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/lina-alchaer\"\"},{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/jessica-evelyn-morris-9572341bb\"\"},{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/kemunto-maranga-010173207\"\"},{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/kelsie-bennett-2523b896\"\"},{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/ashley-fleury-1a1493210\"\"},{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/sarah-del-monte-a6434991\"\"},{\"\"profile_link\"\":\"\"https://www.linkedin.com/in/sammie-fitzgerald-787060161\"\"},{\"\"profile_link\"\":\"\"https://www.linkedin.com/in/kathy-fitzgerald-7832a1a8\"\"},{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/robin-c-rainer\"\"},{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/david-gurman-1bba27138\"\"},{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/casey-swann-72528995\"\"},{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/samueladelaar\"\"},{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/jimmy-weese-66814530\"\"},{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/henryshaver\"\"},{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/kcfitzgerald\"\"},{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/unlapiz\"\"},{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/dorianpearce\"\"},{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/sean-o-grady-72670666\"\"},{\"\"profile_link\"\":\"\"https://ca.linkedin.com/in/shauna-smith-646925b9\"\"},{\"\"profile_link\"\":\"\"https://www.linkedin.com/in/kathrynary\"\"}]\"\\t\"Queen\\'s University Belfast\"\\t\"[{\"\"degree\"\":\"\"Bachelor of Arts (B.A.) Honours\"\"\\t\"\"end_year\"\":\"\"2011\"\"\\t\"\"field\"\":\"\"English Language and Literature\"\"\\t\"\"meta\"\":\"\"2009 - 2011\"\"\\t\"\"start_year\"\":\"\"2009\"\"\\t\"\"title\"\":\"\"Queen\\'s University Belfast\"\"\\t\"\"url\"\":\"\"https://www.linkedin.com/school/queen\\'s-university-belfast/\"\"},{\"\"degree\"\":\"\"Business Analysis Essentials Certification\"\"\\t\"\"end_year\"\":\"\"2021\"\"\\t\"\"field\"\":\"\"Business Analysis\"\"\\t\"\"meta\"\":\"\"2019 - 2021 The Business Analysis Essentials program delivers practical, hands-on, experience-based training in the core knowledge and skills of business analysis. Courses: Fundamentals of Business AnalysisAccelerated Requirements, Elicitation and Analysis Facilitation Techniques for Business AnalystsModelling Business Processes and Workflows Use Case Modelling Validating and Testing Requirements Business Analysis in an Agile Environment\"\"\\t\"\"start_year\"\":\"\"2019\"\"\\t\"\"title\"\":\"\"Algonquin College of Applied Arts and Technology\"\"\\t\"\"url\"\":\"\"https://www.linkedin.com/school/algonquincollege/\"\"},{\"\"degree\"\":\"\"Project Management Essentials Certification\"\"\\t\"\"end_year\"\":\"\"\"\"\\t\"\"field\"\":\"\"Project Management\"\"\\t\"\"meta\"\":\"\"2021 - Present The Project Management Essentials program delivers practical, hands-on training in the core knowledge and skills of the discipline in practice today. Courses completed:- Introduction to Managing Projects- Resource, Communications, and Stakeholder Management\"\"\\t\"\"start_year\"\":\"\"2021\"\"\\t\"\"title\"\":\"\"Algonquin College of Applied Arts and Technology\"\"\\t\"\"url\"\":\"\"https://www.linkedin.com/school/algonquincollege/\"\"},{\"\"degree\"\":\"\"Post Graduate Certificate\"\"\\t\"\"end_year\"\":\"\"2016\"\"\\t\"\"field\"\":\"\"Technical writer\"\"\\t\"\"meta\"\":\"\"2015 - 2016 Produce purpose-driven communicationsWrite task-based and structured documentsInteract with subject matter expertsIncorporate visual language elements into documentsEdit by using a style guidePresent papers through public speaking\"\"\\t\"\"start_year\"\":\"\"2015\"\"\\t\"\"title\"\":\"\"Algonquin College of Applied Arts and Technology\"\"\\t\"\"url\"\":\"\"https://www.linkedin.com/school/algonquincollege/\"\"},{\"\"degree\"\":\"\"Bachelor of Arts (B.A.) Honours\"\"\\t\"\"end_year\"\":\"\"2009\"\"\\t\"\"field\"\":\"\"Psychology with a minor in English Language and Literature\"\"\\t\"\"meta\"\":\"\"2005 - 2009\"\"\\t\"\"start_year\"\":\"\"2005\"\"\\t\"\"title\"\":\"\"Carleton University\"\"\\t\"\"url\"\":\"\"https://www.linkedin.com/school/carleton-university/\"\"}]\"\\t\"https://media.licdn.com/dms/image/C4E03AQEcz_jNRWnyig/profile-displayphoto-shrink_800_800/0/1620309427529?e=2147483647&v=beta&t=YwJc0767ArNyWPqRmnaGbfTKfTG1kMe3Mj-S_4H_rNk\"\\t\"\"\\t\"\"\\t\"\"\\t\"null\"\\t\"\"\\t\"null\"']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "header = rdd_raw.first()\n",
        "rdd_no_header = rdd_raw.filter(lambda line: line != header)\n",
        "print(f\"Total rows (Including header): {rdd_raw.count()}\")\n",
        "print(f\"Total rows (excluding header): {rdd_no_header.count()}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bE2T-tuz1NkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "header_columns = header.split(\"\\t\")\n",
        "header_columns = [col.strip('\"\"').strip().lower() for col in header_columns]\n",
        "\n",
        "print(\"Available Columns:\")\n",
        "for idx, column in enumerate(header_columns):\n",
        "    print(f\"Index: {idx}, Column: {column}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "F65Tikfhw69Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "country_code_index = header_columns.index(\"country_code\")\n",
        "name_index = header_columns.index(\"name\")\n",
        "region_index = header_columns.index(\"region\")\n",
        "company_name_index = header_columns.index(\"current_company:name\")\n",
        "following_index = header_columns.index(\"following\")\n",
        "post_index = header_columns.index(\"posts\")\n",
        "education_index = header_columns.index(\"education\")\n",
        "certification_index = header_columns.index(\"certifications\")\n",
        "recommendations_index = header_columns.index(\"recommendations_count\")"
      ],
      "metadata": {
        "id": "xwmuRuvTFr0m"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rdd_split = rdd_no_header.map(lambda line: line.split(\",\"))\n",
        "\n",
        "def parse_csv_line(lines):\n",
        "    reader = csv.reader(lines, delimiter='\\t')  # Change delimiter if needed\n",
        "    return [row for row in reader]\n",
        "\n",
        "rdd_split = rdd_raw.filter(lambda row: row != header).mapPartitions(parse_csv_line)\n",
        "print (rdd_split.take(1))"
      ],
      "metadata": {
        "id": "xiaiIEDKzo7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def clean_column(code):\n",
        "    cleaned_code = str(code).strip().strip('\"')\n",
        "    if not cleaned_code or cleaned_code.lower() in [\"null\", \"no data\",\"--\"]:\n",
        "        return \"Not Available\"\n",
        "    return cleaned_code"
      ],
      "metadata": {
        "id": "kZM3pqb4444I"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_digit(digit_value):\n",
        "    try:\n",
        "        return int(digit_value) if digit_value.isdigit() else 0\n",
        "    except ValueError:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "x07DzVzW9xEf"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(country_code_index)\n",
        "country_codes_rdd = rdd_split.map(lambda row: clean_column(row[country_code_index]))\n",
        "distinct_countries = country_codes_rdd.distinct().sortBy(lambda x: x.lower()).collect()\n",
        "\n",
        "print(\"Distinct Country Codes:\")\n",
        "for i,country in enumerate(distinct_countries, start=1):\n",
        "    print(f\"{i}. {country}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PnIrrzErxUmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specific_country_code = \"CA\"\n",
        "filtered_profiles_rdd = rdd_split.filter(lambda row: clean_column(row[country_code_index]) == specific_country_code)\n",
        "\n",
        "# Extract names of profiles belonging to the specified country\n",
        "profile_names_rdd = filtered_profiles_rdd.map(lambda row: clean_column(row[name_index]))\n",
        "\n",
        "# Sort and collect unique profile names\n",
        "sorted_profiles = profile_names_rdd.distinct().sortBy(lambda x: x.lower()).collect()\n",
        "\n",
        "print(f\"Profiles from {specific_country_code}:\")\n",
        "for i, profile in enumerate(sorted_profiles, start=1):\n",
        "    print(f\"{i}. {profile}\")\n"
      ],
      "metadata": {
        "id": "cHqlJtIiCH8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regions_rdd  = rdd_split.map(lambda row: (clean_column(row[region_index]), 1))\n",
        "region_counts = regions_rdd.reduceByKey(lambda a, b: a + b)\n",
        "region_counts_result = region_counts.sortBy(lambda x: x).collect()\n",
        "\n",
        "print(\"Region:\" )\n",
        "for region, count in region_counts_result:\n",
        "    print(f\"{region}, Count: {count}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "I53BvbCcSPQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "company_names_rdd = rdd_split.map(lambda row: clean_column(row[company_name_index]))\n",
        "distinct_company_names_rdd = company_names_rdd.distinct().sortBy(lambda x: x.lower()).collect()\n",
        "\n",
        "print(\"Distinct company names:\")\n",
        "for i , company in enumerate(distinct_company_names_rdd,start=1):\n",
        "     print(f\"{i}. {company}\")"
      ],
      "metadata": {
        "id": "_mqJhY5mwXz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "people_rdd = rdd_split.map(lambda row: (\n",
        "    clean_digit(clean_column(row[following_index])),\n",
        "    clean_column(row[name_index])\n",
        "))\n",
        "\n",
        "\n",
        "sorted_people_rdd = people_rdd.sortBy(lambda x: x[0], ascending=False)\n",
        "\n",
        "\n",
        "top_10_followed = sorted_people_rdd.take(10)\n",
        "\n",
        "\n",
        "print(\"Top 10 Most-Followed People:\")\n",
        "for i,(following, name) in enumerate(top_10_followed,start =1):\n",
        "    print(f\"{i}. {name}: {following} followers\")\n"
      ],
      "metadata": {
        "id": "Gm2_BnZzytlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_string(raw_str):\n",
        "    \"\"\"Cleans raw JSON string by fixing formatting issues.\"\"\"\n",
        "    cleaned_str = raw_str.strip()  # Remove leading/trailing spaces\n",
        "    cleaned_str = cleaned_str.replace(\"\\t\", \",\")  # Fix delimiters\n",
        "    cleaned_str = cleaned_str.replace(\"['\", \"[\")  # Fix opening bracket\n",
        "    cleaned_str = cleaned_str.replace(\"']\", \"]\")  # Fix closing bracket\n",
        "    cleaned_str = cleaned_str.replace('\"\"', 'null')  # Handle empty values correctly\n",
        "    return cleaned_str\n",
        "\n",
        "def safe_json_loads(raw_str):\n",
        "    \"\"\"Safely loads JSON string, handling decoding errors.\"\"\"\n",
        "    try:\n",
        "        return json.loads(raw_str)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON Parse Error: {raw_str} | Error: {e}\")  # Debugging output\n",
        "        return None  # Return None for invalid JSON rows"
      ],
      "metadata": {
        "id": "WeO8koQuAM0D"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_profile_likes(row):\n",
        "    \"\"\"Extracts profile name, falling back to 'name' column if attribution is missing.\"\"\"\n",
        "    post_list = safe_json_loads(clean_string(row[post_index]))\n",
        "\n",
        "    if post_list:\n",
        "        extracted_data = []\n",
        "        for post in post_list:\n",
        "            profile_name = post.get(\"attribution\", row[name_index]).replace(\"Liked by \", \"\") if post.get(\"attribution\") else row[name_index]\n",
        "            extracted_data.append((profile_name, 1))\n",
        "        return extracted_data\n",
        "    return []\n",
        "\n",
        "profile_likes_rdd = rdd_split.flatMap(extract_profile_likes)\n",
        "\n",
        "likes_count_rdd = profile_likes_rdd.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "all_profiles_rdd = rdd_split.map(lambda row: row[name_index]).distinct()\n",
        "\n",
        "likes_count_dict = dict(likes_count_rdd.collect())\n",
        "\n",
        "final_sorted_likes_count = sorted([(profile, likes_count_dict.get(profile, 0)) for profile in all_profiles_rdd.collect()], key=lambda x: x[0])\n",
        "\n",
        "print(\"Total Posts Liked Per Profile (Sorted by Name, Including 0 Likes):\")\n",
        "for profile, count in final_sorted_likes_count:\n",
        "    print(f\"{profile}: {count}\")"
      ],
      "metadata": {
        "id": "gTwxHkwn9xCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply cleaning and JSON transformation\n",
        "education_rdd = rdd_split.map(lambda row: safe_json_loads(clean_string(row[education_index]))).filter(lambda x: x is not None)\n",
        "\n",
        "# Debugging output to verify JSON parsing\n",
        "print(\"Cleaned JSON Output:\", education_rdd.take(10))\n",
        "\n",
        "def extract_education_profiles(row):\n",
        "    \"\"\"Extracts education institutions from 'title' tag within JSON, linked to profiles.\"\"\"\n",
        "    education_list = safe_json_loads(clean_string(row[education_index]))  # Convert 'education' column to JSON\n",
        "\n",
        "    if education_list:  # Ensure JSON conversion is valid\n",
        "        extracted_data = []\n",
        "        for education in education_list:\n",
        "            institution = education.get(\"title\", \"Unknown Institution\")  # Get institution name\n",
        "            extracted_data.append((institution, 1))  # Count occurrences\n",
        "        return extracted_data\n",
        "    return []  # Return empty list if no valid education data\n",
        "\n",
        "# Create RDD mapping education institutions to profile counts\n",
        "education_count_rdd = rdd_split.flatMap(extract_education_profiles)\n",
        "\n",
        "# **Aggregate counts for each institution**\n",
        "institution_counts_rdd = education_count_rdd.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# **Extract all unique education institutions to ensure missing entries are shown with `0` counts**\n",
        "all_institutions_rdd = education_rdd.flatMap(lambda edu_list: [edu.get(\"title\", \"Unknown Institution\") for edu in edu_list]).distinct()\n",
        "\n",
        "# Convert counts to a dictionary for lookup\n",
        "institution_count_dict = dict(institution_counts_rdd.collect())\n",
        "\n",
        "# **Ensure missing institutions appear with a count of `0`**\n",
        "final_sorted_institutions = sorted([(institution, institution_count_dict.get(institution, 0)) for institution in all_institutions_rdd.collect()], key=lambda x: x[0].lower())\n",
        "\n",
        "# **Print final sorted results**\n",
        "print(\"Total Profiles by Education Institution (Sorted Alphabetically):\")\n",
        "for institution, count in final_sorted_institutions:\n",
        "    print(f\"{institution}: {count}\")"
      ],
      "metadata": {
        "id": "-w8ltzBG_EBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply cleaning and JSON transformation\n",
        "certification_rdd = rdd_split.map(lambda row: safe_json_loads(clean_string(row[certification_index]))).filter(lambda x: x is not None)\n",
        "\n",
        "# Debugging output to verify JSON parsing\n",
        "print(\"Cleaned JSON Output:\", certification_rdd.take(10))\n",
        "\n",
        "def extract_certification_profiles(row):\n",
        "    \"\"\"Extracts certification names from 'title' tag within JSON, linked to profiles.\"\"\"\n",
        "    certification_list = safe_json_loads(clean_string(row[certification_index]))  # Convert 'certification' column to JSON\n",
        "\n",
        "    if certification_list:  # Ensure JSON conversion is valid\n",
        "        extracted_data = []\n",
        "        for certification in certification_list:\n",
        "            cert_name = certification.get(\"title\", \"Unknown certifications\")  # Get certification name\n",
        "            extracted_data.append((cert_name, 1))  # Count occurrences\n",
        "        return extracted_data\n",
        "    return []  # Return empty list if no valid certification data\n",
        "\n",
        "# Create RDD mapping certifications to profile counts\n",
        "certification_count_rdd = rdd_split.flatMap(extract_certification_profiles)\n",
        "\n",
        "# **Aggregate counts for each certification**\n",
        "certification_counts_rdd = certification_count_rdd.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# **Extract all unique certifications to ensure missing entries are shown with `0` counts**\n",
        "all_certifications_rdd = certification_rdd.flatMap(lambda cert_list: [cert.get(\"title\", \"Unknown certifications\") for cert in cert_list]).distinct()\n",
        "\n",
        "# Convert counts to a dictionary for lookup\n",
        "certification_count_dict = dict(certification_counts_rdd.collect())\n",
        "\n",
        "# **Ensure missing certifications appear with a count of `0`**\n",
        "final_sorted_certifications = sorted([(cert_name, certification_count_dict.get(cert_name, 0)) for cert_name in all_certifications_rdd.collect()], key=lambda x: x[0].lower())\n",
        "\n",
        "# **Print final sorted results**\n",
        "print(\"Total Profiles by certifications (Sorted Alphabetically):\")\n",
        "for cert_name, count in final_sorted_certifications:\n",
        "    print(f\"{cert_name}: {count}\")"
      ],
      "metadata": {
        "id": "Bb_IOzYV-crh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to parse and handle null values\n",
        "def extract_recommendations(row):\n",
        "    \"\"\"Extracts profile names and their corresponding recommendation counts.\"\"\"\n",
        "    name = row[name_index]  # Extract profile name\n",
        "    recommendations = row[recommendations_index]  # Extract recommendations count\n",
        "\n",
        "    # Convert recommendations to integer safely, treating null as 0\n",
        "    recommendations = int(recommendations) if recommendations and recommendations.isdigit() else 0\n",
        "\n",
        "    return (name, recommendations)\n",
        "\n",
        "# Create RDD with extracted recommendation counts\n",
        "recommendations_rdd = rdd_split.map(extract_recommendations)\n",
        "\n",
        "# **Aggregate total recommendations per profile**\n",
        "total_recommendations_rdd = recommendations_rdd.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# **Sort results alphabetically by profile name**\n",
        "sorted_recommendations = total_recommendations_rdd.sortByKey()\n",
        "\n",
        "# **Print final sorted results**\n",
        "print(\"Total Recommendations per Profile (Sorted Alphabetically):\")\n",
        "for name, count in sorted_recommendations.collect():\n",
        "    print(f\"{name}: {count}\")"
      ],
      "metadata": {
        "id": "7BNwEqC9_T5u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
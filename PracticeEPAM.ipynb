{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanarayan/EPAM_PRACTICE/blob/main/PracticeEPAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuTwHbixw97v"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxGPRKL9qS_S"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext\n",
        "import csv,json , re\n",
        "from io import StringIO\n",
        "# Check if a SparkContext already exists\n",
        "try:\n",
        "    sc = SparkContext.getOrCreate()\n",
        "    print(\"Using existing SparkContext\")\n",
        "except ValueError:\n",
        "    # If not, create a new one\n",
        "    sc = SparkContext(\"local\", \"Linkdin Example\")\n",
        "    print(\"Created a new SparkContext\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dF7ElJSt1MO4"
      },
      "outputs": [],
      "source": [
        "rdd  = sc.textFile(\"/content/LinkedIn people profiles datasets.csv\")\n",
        "rdd_raw = rdd.map(lambda line: line.replace(',\"', '\\t\"'))\n",
        "print (rdd_raw.take(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bE2T-tuz1NkO"
      },
      "outputs": [],
      "source": [
        "header = rdd_raw.first()\n",
        "rdd_no_header = rdd_raw.filter(lambda line: line != header)\n",
        "print(f\"Total rows (Including header): {rdd_raw.count()}\")\n",
        "print(f\"Total rows (excluding header): {rdd_no_header.count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F65Tikfhw69Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "header_columns = header.split(\"\\t\")\n",
        "header_columns = [col.strip('\"\"').strip().lower() for col in header_columns]\n",
        "\n",
        "print(\"Available Columns:\")\n",
        "for idx, column in enumerate(header_columns):\n",
        "    print(f\"Index: {idx}, Column: {column}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "xwmuRuvTFr0m"
      },
      "outputs": [],
      "source": [
        "country_code_index = header_columns.index(\"country_code\")\n",
        "name_index = header_columns.index(\"name\")\n",
        "region_index = header_columns.index(\"region\")\n",
        "company_name_index = header_columns.index(\"current_company:name\")\n",
        "following_index = header_columns.index(\"following\")\n",
        "post_index = header_columns.index(\"posts\")\n",
        "education_index = header_columns.index(\"education\")\n",
        "certification_index = header_columns.index(\"certifications\")\n",
        "recommendations_index = header_columns.index(\"recommendations_count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiaiIEDKzo7R"
      },
      "outputs": [],
      "source": [
        "#rdd_split = rdd_no_header.map(lambda line: line.split(\",\"))\n",
        "\n",
        "def parse_csv_line(lines):\n",
        "    reader = csv.reader(lines, delimiter='\\t')  # Change delimiter if needed\n",
        "    return [row for row in reader]\n",
        "\n",
        "rdd_split = rdd_raw.filter(lambda row: row != header)\n",
        "rdd_split = rdd_split.mapPartitions(parse_csv_line)\n",
        "\n",
        "print (rdd_split.take(1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "kZM3pqb4444I"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_column(code):\n",
        "    cleaned_code = str(code).strip().strip('\"')\n",
        "    if not cleaned_code or cleaned_code.lower() in [\"null\", \"no data\",\"--\"]:\n",
        "        return \"Not Available\"\n",
        "    return cleaned_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "x07DzVzW9xEf"
      },
      "outputs": [],
      "source": [
        "def clean_digit(digit_value):\n",
        "    try:\n",
        "        return int(digit_value) if digit_value.isdigit() else 0\n",
        "    except ValueError:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PnIrrzErxUmO"
      },
      "outputs": [],
      "source": [
        "print(country_code_index)\n",
        "country_codes_rdd = rdd_split.map(lambda row: clean_column(row[country_code_index]))\n",
        "distinct_countries = country_codes_rdd.distinct().sortBy(lambda x: x.lower()).collect() #list of string is returned\n",
        "\n",
        "print(\"Distinct Country Codes:\")\n",
        "for i,country in enumerate(distinct_countries, start=1):\n",
        "    print(f\"{i}. {country}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHqlJtIiCH8y"
      },
      "outputs": [],
      "source": [
        "specific_country_code = \"CA\"\n",
        "filtered_profiles_rdd = rdd_split.filter(lambda row: clean_column(row[country_code_index]) == specific_country_code)\n",
        "\n",
        "# Extract names of profiles belonging to the specified country\n",
        "profile_names_rdd = filtered_profiles_rdd.map(lambda row: clean_column(row[name_index]))\n",
        "\n",
        "# Sort and collect unique profile names\n",
        "sorted_profiles = profile_names_rdd.distinct().sortBy(lambda x: x.lower()).collect()\n",
        "\n",
        "print(f\"Profiles from {specific_country_code}:\")\n",
        "for i, profile in enumerate(sorted_profiles, start=1):\n",
        "    print(f\"{i}. {profile}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "I53BvbCcSPQz"
      },
      "outputs": [],
      "source": [
        "regions_rdd  = rdd_split.map(lambda row: (clean_column(row[region_index]), 1))\n",
        "print(regions_rdd.take(5))\n",
        "region_counts = regions_rdd.reduceByKey(lambda a, b: a + b)\n",
        "print(region_counts.take(5))\n",
        "region_counts_result = region_counts.sortBy(lambda x: x).collect()\n",
        "\n",
        "print(\"Region:\" )\n",
        "for i,(region, count) in enumerate(region_counts_result,start =1):\n",
        "    print(f\"{i}. {region}, Count: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mqJhY5mwXz5"
      },
      "outputs": [],
      "source": [
        "company_names_rdd = rdd_split.map(lambda row: clean_column(row[company_name_index]))\n",
        "distinct_company_names_rdd = company_names_rdd.distinct().sortBy(lambda x: x.lower()).collect()\n",
        "\n",
        "print(\"Distinct company names:\")\n",
        "for i , company in enumerate(distinct_company_names_rdd,start=1):\n",
        "     print(f\"{i}. {company}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gm2_BnZzytlY"
      },
      "outputs": [],
      "source": [
        "people_rdd = rdd_split.map(lambda row: (\n",
        "    clean_digit(clean_column(row[following_index])),\n",
        "    clean_column(row[name_index])\n",
        "))\n",
        "\n",
        "print(people_rdd.take(5))\n",
        "sorted_people_rdd = people_rdd.sortBy(lambda x: x[0], ascending=False)\n",
        "\n",
        "\n",
        "top_10_followed = sorted_people_rdd.take(10)\n",
        "\n",
        "\n",
        "print(\"Top 10 Most-Followed People:\")\n",
        "for i,(following, name) in enumerate(top_10_followed,start =1):\n",
        "    print(f\"{i}. {name}: {following} followers\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "WeO8koQuAM0D"
      },
      "outputs": [],
      "source": [
        "def clean_string(raw_str):\n",
        "    \"\"\"Cleans raw JSON string by fixing formatting issues.\"\"\"\n",
        "    cleaned_str = raw_str.strip()  # Remove leading/trailing spaces\n",
        "    cleaned_str = cleaned_str.replace(\"\\t\", \",\")  # Fix delimiters\n",
        "    cleaned_str = cleaned_str.replace(\"['\", \"[\")  # Fix opening bracket\n",
        "    cleaned_str = cleaned_str.replace(\"']\", \"]\")  # Fix closing bracket\n",
        "    cleaned_str = cleaned_str.replace('\"\"', 'null')  # Handle empty values correctly\n",
        "    return cleaned_str\n",
        "\n",
        "def safe_json_loads(raw_str):\n",
        "    \"\"\"Safely loads JSON string, handling decoding errors.\"\"\"\n",
        "    try:\n",
        "        return json.loads(raw_str)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON Parse Error: {raw_str} | Error: {e}\")  # Debugging output\n",
        "        return None  # Return None for invalid JSON rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTwxHkwn9xCr"
      },
      "outputs": [],
      "source": [
        "def extract_profile_likes(row):\n",
        "    \"\"\"Extracts profile name, falling back to 'name' column if attribution is missing.\"\"\"\n",
        "    post_list = safe_json_loads(clean_string(row[post_index]))\n",
        "\n",
        "    if post_list:\n",
        "        extracted_data = []\n",
        "        for post in post_list:\n",
        "            profile_name = post.get(\"attribution\", row[name_index]).replace(\"Liked by \", \"\") if post.get(\"attribution\") else row[name_index]\n",
        "            extracted_data.append((profile_name, 1))\n",
        "        return extracted_data\n",
        "    return []\n",
        "\n",
        "profile_likes_rdd = rdd_split.flatMap(extract_profile_likes)\n",
        "\n",
        "likes_count_rdd = profile_likes_rdd.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "all_profiles_rdd = rdd_split.map(lambda row: row[name_index]).distinct()\n",
        "\n",
        "likes_count_dict = dict(likes_count_rdd.collect())\n",
        "\n",
        "final_sorted_likes_count = sorted([(profile, likes_count_dict.get(profile, 0)) for profile in all_profiles_rdd.collect()], key=lambda x: x[0])\n",
        "\n",
        "print(\"Total Posts Liked Per Profile (Sorted by Name, Including 0 Likes):\")\n",
        "for i,(profile, count) in enumerate(final_sorted_likes_count,start = 1):\n",
        "    print(f\"{i}.{profile}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract education institutions from JSON data\n",
        "def extract_education_profiles(row):\n",
        "    \"\"\"Extracts education institutions from JSON or assigns default if missing.\"\"\"\n",
        "    education_list = safe_json_loads(clean_string(row[education_index])) if row[education_index] else []\n",
        "\n",
        "    # Ensure invalid or empty data gets properly mapped to \"Institution Not Available\"\n",
        "    if not education_list or not isinstance(education_list, list):\n",
        "        return [(\"Institution Not Available\", 1)]\n",
        "\n",
        "    return [(edu.get(\"title\", \"Institution Not Available\"), 1) for edu in education_list]\n",
        "\n",
        "# Mapping institutions to profile counts\n",
        "education_count_rdd = rdd_split.flatMap(extract_education_profiles)\n",
        "\n",
        "\n",
        "# Extract all unique institutions\n",
        "all_institutions_rdd = education_count_rdd.map(lambda x: x[0]).distinct()\n",
        "\n",
        "# Aggregate institution counts\n",
        "institution_counts_rdd = education_count_rdd.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# Convert counts to a dictionary\n",
        "institution_count_dict = dict(institution_counts_rdd.collect())\n",
        "\n",
        "# Directly collect institutions from RDD instead of a separate list\n",
        "final_sorted_institutions = sorted([\n",
        "    (inst, institution_count_dict.get(inst, 0))\n",
        "    for inst in all_institutions_rdd.collect()  # No separate `institutions_list`\n",
        "], key=lambda x: x[0].lower())\n",
        "\n",
        "# Print results\n",
        "print(\"Total Profiles by Education Institution (Sorted Alphabetically):\")\n",
        "for i, (institution, count) in enumerate(final_sorted_institutions,start = 1):\n",
        "    print(f\"{i}.{institution}: {count}\")"
      ],
      "metadata": {
        "id": "QVNKy28qc9cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb_IOzYV-crh"
      },
      "outputs": [],
      "source": [
        "# Apply cleaning and JSON transformation\n",
        "certification_rdd = rdd_split.map(lambda row: safe_json_loads(clean_string(row[certification_index]))).filter(lambda x: x is not None)\n",
        "\n",
        "\n",
        "def extract_certification_profiles(row):\n",
        "    \"\"\"Extracts certification names from 'title' tag within JSON, linked to profiles.\"\"\"\n",
        "    certification_list = safe_json_loads(clean_string(row[certification_index])) if row[certification_index] else [] # Convert 'certification' column to JSON\n",
        "\n",
        "    if certification_list:  # Ensure JSON conversion is valid\n",
        "        extracted_data = []\n",
        "        for certification in certification_list:\n",
        "            cert_name = certification.get(\"title\", \"Unknown certifications\")  # Get certification name\n",
        "            extracted_data.append((cert_name, 1))  # Count occurrences\n",
        "        return extracted_data\n",
        "    return []  # Return empty list if no valid certification data\n",
        "\n",
        "# Create RDD mapping certifications to profile counts\n",
        "certification_count_rdd = rdd_split.flatMap(extract_certification_profiles)\n",
        "\n",
        "# **Aggregate counts for each certification**\n",
        "certification_counts_rdd = certification_count_rdd.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# **Extract all unique certifications to ensure missing entries are shown with `0` counts**\n",
        "all_certifications_rdd = certification_rdd.flatMap(lambda cert_list: [cert.get(\"title\", \"Unknown certifications\") for cert in cert_list]).distinct()\n",
        "\n",
        "# Convert counts to a dictionary for lookup\n",
        "certification_count_dict = dict(certification_counts_rdd.collect())\n",
        "\n",
        "# **Ensure missing certifications appear with a count of `0`**\n",
        "final_sorted_certifications = sorted([(cert_name, certification_count_dict.get(cert_name, 0)) for cert_name in all_certifications_rdd.collect()], key=lambda x: x[0].lower())\n",
        "\n",
        "# **Print final sorted results**\n",
        "print(\"Total Profiles by certifications (Sorted Alphabetically):\")\n",
        "for i,(cert_name, count) in enumerate(final_sorted_certifications,start =1):\n",
        "    print(f\"{i}.{cert_name}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BNwEqC9_T5u"
      },
      "outputs": [],
      "source": [
        "# Function to parse and handle null values\n",
        "def extract_recommendations(row):\n",
        "    \"\"\"Extracts profile names and their corresponding recommendation counts.\"\"\"\n",
        "    name = row[name_index]  # Extract profile name\n",
        "    recommendations = row[recommendations_index]  # Extract recommendations count\n",
        "\n",
        "    # Convert recommendations to integer safely, treating null as 0\n",
        "    recommendations = int(recommendations) if recommendations and recommendations.isdigit() else 0\n",
        "\n",
        "    return (name, recommendations)\n",
        "\n",
        "# Create RDD with extracted recommendation counts\n",
        "recommendations_rdd = rdd_split.map(extract_recommendations).sortByKey()\n",
        "\n",
        "# **Print final sorted results**\n",
        "print(\"Total Recommendations per Profile (Sorted Alphabetically):\")\n",
        "for i,(name, count) in enumerate(recommendations_rdd.collect() ,start =1):\n",
        "    print(f\"{i}.{name}: {count}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMd+r3mFa7TcJVAai3jzk1o",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
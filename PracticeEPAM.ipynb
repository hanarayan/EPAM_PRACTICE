{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanarayan/EPAM_PRACTICE/blob/main/PracticeEPAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuTwHbixw97v"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxGPRKL9qS_S"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext\n",
        "import csv,json , re\n",
        "from io import StringIO\n",
        "# Check if a SparkContext already exists\n",
        "try:\n",
        "    sc = SparkContext.getOrCreate()\n",
        "    print(\"Using existing SparkContext\")\n",
        "except ValueError:\n",
        "    # If not, create a new one\n",
        "    sc = SparkContext(\"local\", \"Linkdin Example\")\n",
        "    print(\"Created a new SparkContext\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dF7ElJSt1MO4"
      },
      "outputs": [],
      "source": [
        "rdd  = sc.textFile(\"/content/LinkedIn people profiles datasets.csv\")\n",
        "rdd_raw = rdd.map(lambda line: line.replace(',\"', '\\t\"'))\n",
        "print (rdd_raw.take(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bE2T-tuz1NkO"
      },
      "outputs": [],
      "source": [
        "header = rdd_raw.first()\n",
        "rdd_no_header = rdd_raw.filter(lambda line: line != header)\n",
        "print(f\"Total rows (Including header): {rdd_raw.count()}\")\n",
        "print(f\"Total rows (excluding header): {rdd_no_header.count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F65Tikfhw69Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "header_columns = header.split(\"\\t\")\n",
        "header_columns = [col.strip('\"\"').strip().lower() for col in header_columns]\n",
        "\n",
        "print(\"Available Columns:\")\n",
        "for idx, column in enumerate(header_columns):\n",
        "    print(f\"Index: {idx}, Column: {column}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwmuRuvTFr0m"
      },
      "outputs": [],
      "source": [
        "country_code_index = header_columns.index(\"country_code\")\n",
        "name_index = header_columns.index(\"name\")\n",
        "region_index = header_columns.index(\"region\")\n",
        "company_name_index = header_columns.index(\"current_company:name\")\n",
        "following_index = header_columns.index(\"following\")\n",
        "post_index = header_columns.index(\"posts\")\n",
        "education_index = header_columns.index(\"education\")\n",
        "certification_index = header_columns.index(\"certifications\")\n",
        "recommendations_index = header_columns.index(\"recommendations_count\")\n",
        "position_index = header_columns.index(\"position\")\n",
        "languages_index = header_columns.index(\"languages\")\n",
        "about_index = header_columns.index(\"about\")\n",
        "gropus_index = header_columns.index(\"groups\")\n",
        "volunteer_experience_index = header_columns.index(\"volunteer_experience\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiaiIEDKzo7R"
      },
      "outputs": [],
      "source": [
        "#rdd_split = rdd_no_header.map(lambda line: line.split(\",\"))\n",
        "\n",
        "def parse_csv_line(lines):\n",
        "    reader = csv.reader(lines, delimiter='\\t')  # Change delimiter if needed\n",
        "    return [row for row in reader]\n",
        "\n",
        "rdd_split = rdd_raw.filter(lambda row: row != header)\n",
        "rdd_split = rdd_split.mapPartitions(parse_csv_line)\n",
        "\n",
        "print (rdd_split.take(1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZM3pqb4444I"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_column(code):\n",
        "    cleaned_code = str(code).strip().strip('\"')\n",
        "    if not cleaned_code or cleaned_code.lower() in [\"null\", \"no data\",\"--\"]:\n",
        "        return \"Not Available\"\n",
        "    return cleaned_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x07DzVzW9xEf"
      },
      "outputs": [],
      "source": [
        "def clean_digit(digit_value):\n",
        "    try:\n",
        "        return int(digit_value) if digit_value.isdigit() else 0\n",
        "    except ValueError:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PnIrrzErxUmO"
      },
      "outputs": [],
      "source": [
        "print(country_code_index)\n",
        "country_codes_rdd = rdd_split.map(lambda row: clean_column(row[country_code_index]))\n",
        "distinct_countries = country_codes_rdd.distinct().sortBy(lambda x: x.lower()).collect() #list of string is returned\n",
        "\n",
        "print(\"Distinct Country Codes:\")\n",
        "for i,country in enumerate(distinct_countries, start=1):\n",
        "    print(f\"{i}. {country}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHqlJtIiCH8y"
      },
      "outputs": [],
      "source": [
        "specific_country_code = \"CA\"\n",
        "filtered_profiles_rdd = rdd_split.filter(lambda row: clean_column(row[country_code_index]) == specific_country_code)\n",
        "\n",
        "# Extract names of profiles belonging to the specified country\n",
        "profile_names_rdd = filtered_profiles_rdd.map(lambda row: clean_column(row[name_index]))\n",
        "\n",
        "# Sort and collect unique profile names\n",
        "sorted_profiles = profile_names_rdd.distinct().sortBy(lambda x: x.lower()).collect()\n",
        "\n",
        "print(f\"Profiles from {specific_country_code}:\")\n",
        "for i, profile in enumerate(sorted_profiles, start=1):\n",
        "    print(f\"{i}. {profile}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "I53BvbCcSPQz"
      },
      "outputs": [],
      "source": [
        "regions_rdd  = rdd_split.map(lambda row: (clean_column(row[region_index]), 1))\n",
        "print(regions_rdd.take(5))\n",
        "region_counts = regions_rdd.reduceByKey(lambda a, b: a + b)\n",
        "print(region_counts.take(5))\n",
        "region_counts_result = region_counts.sortBy(lambda x: x).collect()\n",
        "\n",
        "print(\"Region:\" )\n",
        "for i,(region, count) in enumerate(region_counts_result,start =1):\n",
        "    print(f\"{i}. {region}, Count: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mqJhY5mwXz5"
      },
      "outputs": [],
      "source": [
        "company_names_rdd = rdd_split.map(lambda row: clean_column(row[company_name_index]))\n",
        "distinct_company_names_rdd = company_names_rdd.distinct().sortBy(lambda x: x.lower()).collect()\n",
        "\n",
        "print(\"Distinct company names:\")\n",
        "for i , company in enumerate(distinct_company_names_rdd,start=1):\n",
        "     print(f\"{i}. {company}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gm2_BnZzytlY"
      },
      "outputs": [],
      "source": [
        "people_rdd = rdd_split.map(lambda row: (\n",
        "    clean_digit(clean_column(row[following_index])),\n",
        "    clean_column(row[name_index])\n",
        "))\n",
        "\n",
        "print(people_rdd.take(5))\n",
        "sorted_people_rdd = people_rdd.sortBy(lambda x: x[0], ascending=False)\n",
        "\n",
        "\n",
        "top_10_followed = sorted_people_rdd.take(10)\n",
        "\n",
        "\n",
        "print(\"Top 10 Most-Followed People:\")\n",
        "for i,(following, name) in enumerate(top_10_followed,start =1):\n",
        "    print(f\"{i}. {name}: {following} followers\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_5_followed = sorted_people_rdd.take(5)\n",
        "\n",
        "\n",
        "print(\"Top 5 Most-Followed People:\")\n",
        "for i,(following, name) in enumerate(top_5_followed,start =1):\n",
        "    print(f\"{i}. {name}: {following} followers\")"
      ],
      "metadata": {
        "id": "jHhA1WKhwo6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeO8koQuAM0D"
      },
      "outputs": [],
      "source": [
        "def clean_string(raw_str):\n",
        "    \"\"\"Cleans raw JSON string by fixing formatting issues.\"\"\"\n",
        "    cleaned_str = raw_str.strip()  # Remove leading/trailing spaces\n",
        "    cleaned_str = cleaned_str.replace(\"\\t\", \",\")  # Fix delimiters\n",
        "    cleaned_str = cleaned_str.replace(\"['\", \"[\")  # Fix opening bracket\n",
        "    cleaned_str = cleaned_str.replace(\"']\", \"]\")  # Fix closing bracket\n",
        "    cleaned_str = cleaned_str.replace('\"\"', 'null')  # Handle empty values correctly\n",
        "    return cleaned_str\n",
        "\n",
        "def safe_json_loads(raw_str):\n",
        "    \"\"\"Safely loads JSON string, handling decoding errors.\"\"\"\n",
        "    try:\n",
        "        return json.loads(raw_str)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON Parse Error: {raw_str} | Error: {e}\")  # Debugging output\n",
        "        return None  # Return None for invalid JSON rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTwxHkwn9xCr"
      },
      "outputs": [],
      "source": [
        "def extract_profile_likes(row):\n",
        "    \"\"\"Extracts profile name, falling back to 'name' column if attribution is missing.\"\"\"\n",
        "    post_list = safe_json_loads(clean_string(row[post_index]))\n",
        "\n",
        "    if post_list:\n",
        "        extracted_data = []\n",
        "        for post in post_list:\n",
        "            profile_name = post.get(\"attribution\", row[name_index]).replace(\"Liked by \", \"\") if post.get(\"attribution\") else row[name_index]\n",
        "            extracted_data.append((profile_name, 1))\n",
        "        return extracted_data\n",
        "    return []\n",
        "\n",
        "profile_likes_rdd = rdd_split.flatMap(extract_profile_likes)\n",
        "\n",
        "likes_count_rdd = profile_likes_rdd.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "all_profiles_rdd = rdd_split.map(lambda row: row[name_index]).distinct()\n",
        "\n",
        "likes_count_dict = dict(likes_count_rdd.collect())\n",
        "\n",
        "final_sorted_likes_count = sorted([(profile, likes_count_dict.get(profile, 0)) for profile in all_profiles_rdd.collect()], key=lambda x: x[0])\n",
        "\n",
        "print(\"Total Posts Liked Per Profile (Sorted by Name, Including 0 Likes):\")\n",
        "for i,(profile, count) in enumerate(final_sorted_likes_count,start = 1):\n",
        "    print(f\"{i}.{profile}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract education institutions from JSON data\n",
        "def extract_education_profiles(row):\n",
        "    \"\"\"Extracts education institutions from JSON or assigns default if missing.\"\"\"\n",
        "    education_list = safe_json_loads(clean_string(row[education_index])) if row[education_index] else []\n",
        "\n",
        "    # Ensure invalid or empty data gets properly mapped to \"Institution Not Available\"\n",
        "    if not education_list or not isinstance(education_list, list):\n",
        "        return [(\"Institution Not Available\", 1)]\n",
        "\n",
        "    return [(edu.get(\"title\", \"Institution Not Available\"), 1) for edu in education_list]\n",
        "\n",
        "# Mapping institutions to profile counts\n",
        "education_count_rdd = rdd_split.flatMap(extract_education_profiles)\n",
        "\n",
        "\n",
        "# Extract all unique institutions\n",
        "all_institutions_rdd = education_count_rdd.map(lambda x: x[0]).distinct()\n",
        "\n",
        "# Aggregate institution counts\n",
        "institution_counts_rdd = education_count_rdd.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# Convert counts to a dictionary\n",
        "institution_count_dict = dict(institution_counts_rdd.collect())\n",
        "\n",
        "# Directly collect institutions from RDD instead of a separate list\n",
        "final_sorted_institutions = sorted([\n",
        "    (inst, institution_count_dict.get(inst, 0))\n",
        "    for inst in all_institutions_rdd.collect()  # No separate `institutions_list`\n",
        "], key=lambda x: x[0].lower())\n",
        "\n",
        "# Print results\n",
        "print(\"Total Profiles by Education Institution (Sorted Alphabetically):\")\n",
        "for i, (institution, count) in enumerate(final_sorted_institutions,start = 1):\n",
        "    print(f\"{i}.{institution}: {count}\")"
      ],
      "metadata": {
        "id": "QVNKy28qc9cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_degree_title(row):\n",
        "    education_data = safe_json_loads(clean_string(row[education_index]))\n",
        "    if education_data:\n",
        "        for edu in education_data:\n",
        "            degree = edu.get(\"degree\", \"\")\n",
        "            title = edu.get(\"title\", \"\")\n",
        "            if degree and title:\n",
        "                return ((degree, title), 1)  # Return a tuple with key (degree, title) and value 1\n",
        "    return None\n",
        "\n",
        "degree_title_rdd = rdd_split.map(extract_degree_title).filter(lambda x: x is not None)\n",
        "degree_title_counts = degree_title_rdd.reduceByKey(lambda a,b: a+b)\n",
        "\n",
        "print(\"Degree, Title, Profile Count:\")\n",
        "for i, (degree_title, count) in enumerate(degree_title_counts.collect(), start=1):  # unpack to (degree_title, count)\n",
        "    degree, title = degree_title  # unpack the key to (degree, title)\n",
        "    print(f\"{i}. Degree: {degree}, Title: {title}, Count: {count}\")"
      ],
      "metadata": {
        "id": "w_7wISTHtc0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb_IOzYV-crh"
      },
      "outputs": [],
      "source": [
        "# Apply cleaning and JSON transformation\n",
        "certification_rdd = rdd_split.map(lambda row: safe_json_loads(clean_string(row[certification_index]))).filter(lambda x: x is not None)\n",
        "\n",
        "\n",
        "def extract_certification_profiles(row):\n",
        "    \"\"\"Extracts certification names from 'title' tag within JSON, linked to profiles.\"\"\"\n",
        "    certification_list = safe_json_loads(clean_string(row[certification_index])) if row[certification_index] else [] # Convert 'certification' column to JSON\n",
        "\n",
        "    if certification_list:  # Ensure JSON conversion is valid\n",
        "        extracted_data = []\n",
        "        for certification in certification_list:\n",
        "            cert_name = certification.get(\"title\", \"Unknown certifications\")  # Get certification name\n",
        "            extracted_data.append((cert_name, 1))  # Count occurrences\n",
        "        return extracted_data\n",
        "    return []  # Return empty list if no valid certification data\n",
        "\n",
        "# Create RDD mapping certifications to profile counts\n",
        "certification_count_rdd = rdd_split.flatMap(extract_certification_profiles)\n",
        "\n",
        "# **Aggregate counts for each certification**\n",
        "certification_counts_rdd = certification_count_rdd.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# **Extract all unique certifications to ensure missing entries are shown with `0` counts**\n",
        "all_certifications_rdd = certification_rdd.flatMap(lambda cert_list: [cert.get(\"title\", \"Unknown certifications\") for cert in cert_list]).distinct()\n",
        "\n",
        "# Convert counts to a dictionary for lookup\n",
        "certification_count_dict = dict(certification_counts_rdd.collect())\n",
        "\n",
        "# **Ensure missing certifications appear with a count of `0`**\n",
        "final_sorted_certifications = sorted([(cert_name, certification_count_dict.get(cert_name, 0)) for cert_name in all_certifications_rdd.collect()], key=lambda x: x[0].lower())\n",
        "\n",
        "# **Print final sorted results**\n",
        "print(\"Total Profiles by certifications (Sorted Alphabetically):\")\n",
        "for i,(cert_name, count) in enumerate(final_sorted_certifications,start =1):\n",
        "    print(f\"{i}.{cert_name}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BNwEqC9_T5u"
      },
      "outputs": [],
      "source": [
        "# Function to parse and handle null values\n",
        "def extract_recommendations(row):\n",
        "    \"\"\"Extracts profile names and their corresponding recommendation counts.\"\"\"\n",
        "    name = row[name_index]  # Extract profile name\n",
        "    recommendations = row[recommendations_index]  # Extract recommendations count\n",
        "\n",
        "    # Convert recommendations to integer safely, treating null as 0\n",
        "    recommendations = int(recommendations) if recommendations and recommendations.isdigit() else 0\n",
        "\n",
        "    return (name, recommendations)\n",
        "\n",
        "# Create RDD with extracted recommendation counts\n",
        "recommendations_rdd = rdd_split.map(extract_recommendations).sortByKey()\n",
        "\n",
        "# **Print final sorted results**\n",
        "print(\"Total Recommendations per Profile (Sorted Alphabetically):\")\n",
        "for i,(name, count) in enumerate(recommendations_rdd.collect() ,start =1):\n",
        "    print(f\"{i}.{name}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_country_recommendations(row):\n",
        "    \"\"\"Extracts country code and recommendation count.\"\"\"\n",
        "    country = clean_column(row[country_code_index])\n",
        "    recommendations = clean_digit(clean_column(row[recommendations_index]))\n",
        "    return (country, recommendations)\n",
        "\n",
        "country_recommendations_rdd = rdd_split.map(extract_country_recommendations)\n",
        "\n",
        "# Sum of recommendations and count of profiles per country\n",
        "country_stats_rdd = country_recommendations_rdd.mapValues(lambda value: (value, 1))\\\n",
        "                                               .reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1]))\n",
        "\n",
        "# Compute the average recommendations per country\n",
        "average_recommendations_rdd = country_stats_rdd.mapValues(lambda stats: stats[0] / stats[1])\n",
        "\n",
        "\n",
        "# Sort and collect the results\n",
        "sorted_average_recommendations = average_recommendations_rdd.sortByKey().collect()\n",
        "\n",
        "# Print the average recommendations per country\n",
        "print(\"Average Recommendations per Country:\")\n",
        "for country, avg_recommendations in sorted_average_recommendations:\n",
        "    print(f\"{country}: {avg_recommendations}\")\n"
      ],
      "metadata": {
        "id": "ZCxksrNlx5yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Filter out recommendations greater than 3\n",
        "filtered_recommendations_rdd = recommendations_rdd.filter(lambda x: x[1] > 3)\n",
        "\n",
        "# Sort the filtered recommendations alphabetically by name\n",
        "sorted_recommendations_rdd = filtered_recommendations_rdd.sortByKey()\n",
        "\n",
        "# Print the sorted recommendations\n",
        "print(\"Total Recommendations per Profile (greater than 3, Sorted Alphabetically):\")\n",
        "for i, (name, count) in enumerate(sorted_recommendations_rdd.collect(), start=1):\n",
        "    print(f\"{i}. {name}: {count}\")\n"
      ],
      "metadata": {
        "id": "a35eNUHBslyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "position_rdd = rdd_split.map(lambda row: (clean_column(row[position_index]), 1))\n",
        "position_rdd = position_rdd.filter(lambda x: x[0] != \"Not Available\") #filter out \"Not Available\"\n",
        "\n",
        "position_counts = position_rdd.reduceByKey(lambda a, b: a + b)\n",
        "most_frequent_position = position_counts.sortBy(lambda x: x[1], ascending=False)\n",
        "most_frequent_position_result = most_frequent_position.take(10)\n",
        "print(\"Top 10 most frequent positions:\")\n",
        "for i,(position,count) in enumerate(most_frequent_position_result,start =1):\n",
        "    print(f\"{i}. {position}: {count}\")"
      ],
      "metadata": {
        "id": "hr3Dt3Jgm6gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "company_profile_counts = rdd_split.map(lambda row: (clean_column(row[company_name_index]), 1))\n",
        "company_profile_counts = company_profile_counts.reduceByKey(lambda x,y: x+y)\n",
        "\n",
        "# Sort by company name alphabetically\n",
        "sorted_company_counts = company_profile_counts.sortByKey()\n",
        "\n",
        "\n",
        "print(\"Number of profiles per company (Sorted Alphabetically):\")\n",
        "for i,(company, count) in enumerate(sorted_company_counts.collect(),start=1):\n",
        "    print(f\"{i}.{company}: {count}\")\n"
      ],
      "metadata": {
        "id": "-5pR6iRYpejS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_language_titles(row):\n",
        "    \"\"\"Extracts language titles from the 'languages' column.\"\"\"\n",
        "    try:\n",
        "        languages_data = json.loads(clean_string(row[languages_index]))\n",
        "        if isinstance(languages_data, list):\n",
        "            return [lang.get(\"title\", \"Unknown Language\") for lang in languages_data]\n",
        "        else:\n",
        "            return [\"Unknown Language\"]  # Handle cases where languages is not a list\n",
        "    except (json.JSONDecodeError, TypeError, IndexError):\n",
        "        return [\"Unknown Language\"]  # Handle invalid JSON or missing data\n",
        "\n",
        "\n",
        "language_titles_rdd = rdd_split.flatMap(extract_language_titles)\n",
        "distinct_language_titles = language_titles_rdd.distinct().sortBy(lambda x: x.lower()).collect()\n",
        "\n",
        "\n",
        "print(\"Distinct Language Titles (Sorted Alphabetically):\")\n",
        "for i, title in enumerate(distinct_language_titles, start=1):\n",
        "    print(f\"{i}. {title}\")\n"
      ],
      "metadata": {
        "id": "yk0jp-Awrodi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_data_manager(row):\n",
        "    about = clean_column(row[about_index]).lower()\n",
        "    position = clean_column(row[position_index]).lower()\n",
        "    return \"data manager\" in about or \"data manager\" in position\n",
        "\n",
        "# Filter the RDD for profiles mentioning \"Data Manager\"\n",
        "data_manager_profiles_rdd = rdd_split.filter(is_data_manager)\n",
        "\n",
        "# Extract distinct profile names and sort them\n",
        "distinct_data_manager_profiles = data_manager_profiles_rdd.map(lambda row: clean_column(row[name_index])).distinct().sortBy(lambda x: x.lower()).collect()\n",
        "\n",
        "\n",
        "# Print the distinct profiles with serial numbers\n",
        "print(\"Distinct profiles mentioning 'Data Manager' (Sorted Alphabetically):\")\n",
        "for i, profile in enumerate(distinct_data_manager_profiles, start=1):\n",
        "    print(f\"{i}. {profile}\")\n"
      ],
      "metadata": {
        "id": "faaLoGxZv4bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_group_info(row):\n",
        "    \"\"\"Extracts group information and counts profiles per tag title.\"\"\"\n",
        "    try:\n",
        "        groups_data = json.loads(clean_string(row[gropus_index]))\n",
        "        if isinstance(groups_data, list):\n",
        "            for group in groups_data:\n",
        "                title = group.get(\"title\", \"Unknown Group\")\n",
        "                yield (title, 1)\n",
        "    except (json.JSONDecodeError, TypeError):\n",
        "        yield (\"Unknown Group\", 1)  # Handle invalid JSON or missing data\n",
        "\n",
        "# Extract group information\n",
        "group_info_rdd = rdd_split.flatMap(extract_group_info)\n",
        "\n",
        "# Count profiles per group\n",
        "group_counts_rdd = group_info_rdd.reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "# Sort group counts alphabetically by group title\n",
        "sorted_group_counts = group_counts_rdd.sortByKey().collect()\n",
        "\n",
        "# Print the results with serial numbers\n",
        "print(\"Number of profiles per group (Sorted Alphabetically):\")\n",
        "for i, (group_title, count) in enumerate(sorted_group_counts, start=1):\n",
        "    print(f\"{i}. {group_title}: {count}\")\n"
      ],
      "metadata": {
        "id": "0Fhp7XELzyN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_volunteer_titles(row):\n",
        "    \"\"\"Extracts volunteer titles from the 'volunteer_experience' column.\"\"\"\n",
        "    try:\n",
        "        volunteer_data = json.loads(clean_string(row[volunteer_experience_index]))\n",
        "        if isinstance(volunteer_data, list):\n",
        "            for vol in volunteer_data:\n",
        "                title = vol.get(\"title\", \"Unknown Volunteer Experience\")\n",
        "                if \"volunteer\" in title.lower():\n",
        "                    yield (title, 1)\n",
        "    except (json.JSONDecodeError, TypeError):\n",
        "        yield (\"Unknown Volunteer Experience\", 1)\n",
        "\n",
        "volunteer_titles_rdd = rdd_split.flatMap(extract_volunteer_titles)\n",
        "volunteer_title_counts = volunteer_titles_rdd.reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "# Sort the volunteer title counts in descending order of frequency\n",
        "sorted_volunteer_title_counts = volunteer_title_counts.sortBy(lambda x: x[0] ).collect()\n",
        "\n",
        "print(\"Frequency of Volunteer Titles (Sorted by Frequency):\")\n",
        "for i, (title, count) in enumerate(sorted_volunteer_title_counts, start=1):\n",
        "    print(f\"{i}. {title}: {count}\")\n"
      ],
      "metadata": {
        "id": "Armc552b066C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7YR130qMumy4YvowUgMiA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
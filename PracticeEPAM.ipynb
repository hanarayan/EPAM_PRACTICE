{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRAW7b3VaESSSyjsGgcoRM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanarayan/EPAM_PRACTICE/blob/main/PracticeEPAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y git\n",
        "!git config --global user.name \"harnarayan\"\n",
        "!git config --global user.email \"himanshukhatri18@gmail.com\"\n",
        "!git clone https://github.com/hanarayan/EPAM_PRACTICE.git\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuTwHbixw97v",
        "outputId": "597ceba1-8f74-4692-9e5f-1986386e425a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "fatal: destination path 'EPAM_PRACTICE' already exists and is not an empty directory.\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxGPRKL9qS_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d09c4de-37c6-4158-fa06-c34085d2f793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing SparkContext\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkContext\n",
        "\n",
        "# Check if a SparkContext already exists\n",
        "try:\n",
        "    sc = SparkContext.getOrCreate()\n",
        "    print(\"Using existing SparkContext\")\n",
        "except ValueError:\n",
        "    # If not, create a new one\n",
        "    sc = SparkContext(\"local\", \"FlatMap Example\")\n",
        "    print(\"Created a new SparkContext\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file as an RDD\n",
        "rdd = sc.textFile(\"/content/LinkedIn people profiles datasets.csv\")\n"
      ],
      "metadata": {
        "id": "dF7ElJSt1MO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dont consider the header\n",
        "header = rdd.first()\n",
        "rdd_no_header = rdd.filter(lambda line: line != header)\n",
        "print(f\"Total rows (Including header): {rdd.count()}\")\n",
        "print(f\"Total rows (excluding header): {rdd_no_header.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bE2T-tuz1NkO",
        "outputId": "1bf38e50-aa0a-4c0b-f582-53827038d9fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows (Including header): 1001\n",
            "Total rows (excluding header): 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split each row into columns\n",
        "rdd_split = rdd_no_header.map(lambda line: line.split(\",\"))\n",
        "\n",
        "header_columns = header.split(\",\")\n",
        "\n",
        "# Convert column names to lowercase and remove leading/trailing spaces for comparison\n",
        "header_columns = [col.strip('\"\"').strip().lower() for col in header_columns]\n",
        "\n",
        "print(\"Available Columns:\")\n",
        "for column in header_columns:\n",
        "    print(column)\n",
        "\n",
        "country_code_index = header_columns.index(\"country_code\")\n",
        "\n",
        "# Extract country codes from the relevant column\n",
        "country_codes_rdd = rdd_split.map(lambda row: row[country_code_index])\n",
        "\n",
        "# Get distinct country codes\n",
        "distinct_countries = (\n",
        "    rdd_split.map(lambda row: row[country_code_index].strip('\"').strip())  # Remove extra quotes\n",
        "    .distinct()\n",
        "    .collect()\n",
        ")\n",
        "\n",
        "#Print the distinct country codes\n",
        "print(\"Distinct Country Codes:\")\n",
        "for country in distinct_countries:\n",
        "    print(country)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PnIrrzErxUmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "region_index = header_columns.index(\"region\")\n",
        "regions_rdd  = rdd_split.map(lambda row: (row[region_index].strip('\"').strip(), 1))\n",
        "region_counts = regions_rdd.reduceByKey(lambda a, b: a + b)\n",
        "region_counts_result = region_counts.collect()\n",
        "for region, count in region_counts_result:\n",
        "    print(f\"Region: {region}, Count: {count}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "I53BvbCcSPQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NuCEDB9xqVOs"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SlSejBYZr7ut"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}